name: Crawler

on:
  schedule:
    - cron: '03,11,19,36,51 22 * * *'
    - cron: '11 0,23 * * *'
    - cron: '17 2-14/4 * * *'
  repository_dispatch:
    types:
      - start_crawl

env:
  TZ: Asia/Tokyo

jobs:
  crawler:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Checkout
        uses: actions/checkout@v2
        with:
          ref: main
          path: data
      - name: Run
        run: |
          docker-compose run --rm crawler
        env:
          COMPOSE_FILE: docker-compose.crawler.yml
          WORKDIR: /var/app/eiketsu-taisen-data
          CRAWLER_IMAGE: ghcr.io/${{ github.repository }}:crawler
          PUPPETEER_NAVIGATION_TIMEOUT: 120000
          TARGET_URL: https://eiketsu-taisen.net/datalist/
          GIT_USER_NAME: 'eiketsu-taisen-data BOT'
          GIT_USER_EMAIL: 'eiketsu-taisen-data@example.com'
          CLIENT_USER_AGENT: ${{ secrets.CLIENT_USER_AGENT }}
          SLACK_TOKEN: ${{ secrets.SLACK_TOKEN }}
          SLACK_INFO_CHANNEL_ID: ${{ secrets.SLACK_INFO_CHANNEL_ID }}
          SLACK_ERROR_CHANNEL_ID: ${{ secrets.SLACK_ERROR_CHANNEL_ID }}
      - name: Push
        working-directory: data
        run: |
          git push
